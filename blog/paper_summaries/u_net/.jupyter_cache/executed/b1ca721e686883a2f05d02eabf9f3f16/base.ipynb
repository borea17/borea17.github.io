{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f6be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  pio.renderers.default = \"notebook_connected\"\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'/home/borea17/GIT/borea17.github.io/blog/paper_summaries/u_net':\n",
    "  os.chdir(r'/home/borea17/GIT/borea17.github.io/blog/paper_summaries/u_net')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "  \n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69370d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    num_img, img_size = 30, 512\n",
    "    # initialize\n",
    "    imgs = torch.zeros(num_img, 1, img_size, img_size)\n",
    "    labels = torch.zeros(num_img, 1, img_size, img_size)\n",
    "    # fill tensors with data\n",
    "    for index in range(num_img):\n",
    "        cur_name = str(index) + '.png'\n",
    "\n",
    "        img_frame = Image.open('./Dataset/train/image/' + cur_name)\n",
    "        label_frame = Image.open('./Dataset/train/label/' + cur_name)\n",
    "\n",
    "        imgs[index] = transforms.ToTensor()(img_frame).type(torch.float32)\n",
    "        labels[index] = transforms.ToTensor()(label_frame).type(torch.float32)\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "imgs, labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ceaf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.signal import convolve2d\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "class EM_Dataset(Dataset):\n",
    "    \"\"\"EM Dataset (from ISBI 2012) to train U-Net on including data\n",
    "    augmentation as proposed by Ronneberger et al. (2015)\n",
    "\n",
    "    Args:\n",
    "        imgs (tensor): torch tensor containing input images [1, 512, 512]\n",
    "        labels (tensor): torch tensor containing segmented images [1, 512, 512]\n",
    "        stride (int): stride that is used for overlap-tile strategy,\n",
    "            Note: stride must be chosen such that all labels are retrieved\n",
    "        transformation (bool): transform should be applied (True) or not (False)\n",
    "    ------- transformation related -------\n",
    "        probability (float): probability that transformation is applied\n",
    "        alpha (float): intensity of elastic deformation\n",
    "        sigma (float): std dev. of Gaussian kernel, i.e., smoothing parameter\n",
    "        kernel dim (int): kernel size is [kernel_dim, kernel_dim]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, imgs, labels, stride, transformation=False,\n",
    "                 probability=None, alpha=None, sigma=None, kernel_dim=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(stride, int) and stride <= 124 and \\\n",
    "          round((512-388)/stride) == (512-388)/stride\n",
    "        self.orig_imgs = imgs\n",
    "        self.imgs = EM_Dataset._extrapolate_by_mirroring(imgs)\n",
    "        self.labels = labels\n",
    "        self.stride = stride\n",
    "        self.transformation = transformation\n",
    "        if transformation:\n",
    "            assert 0 <= probability <= 1\n",
    "            self.probability = probability\n",
    "            self.alpha = alpha\n",
    "            self.kernel = EM_Dataset._create_gaussian_kernel(kernel_dim, sigma)\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"images and labels are divided into several overlaping parts using the\n",
    "        overlap-tile strategy\n",
    "        \"\"\"\n",
    "        number_of_tiles_1D = (1 + int((512 - 388)/self.stride))\n",
    "        number_of_tiles_2D = number_of_tiles_1D**2\n",
    "\n",
    "        img_index = int(index/number_of_tiles_2D)\n",
    "        # tile indexes of image\n",
    "        tile_index = (index % number_of_tiles_2D)\n",
    "        tile_index_x = (tile_index % number_of_tiles_1D) * self.stride\n",
    "        tile_index_y = int(tile_index / number_of_tiles_1D) * self.stride\n",
    "\n",
    "        img = self.imgs[img_index, :,\n",
    "                        tile_index_y:tile_index_y + 572,\n",
    "                        tile_index_x:tile_index_x + 572]\n",
    "        label = self.labels[img_index, :,\n",
    "                            tile_index_y: tile_index_y + 388,\n",
    "                            tile_index_x: tile_index_x + 388]\n",
    "        if self.transformation:\n",
    "            if np.random.random() > 1 - self.probability:\n",
    "                img, label = EM_Dataset.elastic_deform(img, label, self.alpha,\n",
    "                                                       self.kernel)\n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        number_of_imgs = len(self.imgs)\n",
    "        number_of_tiles = (1 + int((512 - 388)/self.stride))**2\n",
    "        return number_of_imgs * number_of_tiles\n",
    "\n",
    "    @staticmethod\n",
    "    def gray_value_variations(image, sigma):\n",
    "        \"\"\"applies gray value variations by adding Gaussian noise\n",
    "\n",
    "        Args:\n",
    "            image (torch tensor): extrapolated image tensor [1, 572, 572]\n",
    "            sigma (float): std. dev. of Gaussian distribution\n",
    "\n",
    "        Returns:\n",
    "            image (torch tensor): image tensor w. gray value var. [1, 572, 572]\n",
    "        \"\"\"\n",
    "        # see https://stats.stackexchange.com/a/383976\n",
    "        noise = torch.randn(image.shape, dtype=torch.float32) * sigma\n",
    "        return image + noise\n",
    "\n",
    "    @staticmethod\n",
    "    def affine_transform(image, label, angle, translate):\n",
    "        \"\"\"applies random affine translations and rotation on image and label\n",
    "\n",
    "        Args:\n",
    "            image (torch tensor): extrapolated image tensor [1, 572, 572]\n",
    "            label (torch tensor): label tensor [1, 388, 388]\n",
    "            angle (float): rotation angle\n",
    "            translate (list): entries correspond to horizontal and vertical shift\n",
    "\n",
    "        Returns:\n",
    "            image (torch tensor): transformed image tensor [1, 572, 572]\n",
    "            label (torch tensor): transformed label tensor [1, 388, 388]\n",
    "        \"\"\"\n",
    "        # transform to PIL\n",
    "        image = transforms.ToPILImage()(image[0])\n",
    "        label = transforms.ToPILImage()(label[0])\n",
    "        # apply affine transformation\n",
    "        image = TF.affine(image, angle=angle, translate=translate,\n",
    "                          scale=1, shear=0)\n",
    "        label = TF.affine(label, angle=angle, translate=translate,\n",
    "                          scale=1, shear=0)\n",
    "        # transform back to tensor\n",
    "        image = transforms.ToTensor()(np.array(image))\n",
    "        label = transforms.ToTensor()(np.array(label))\n",
    "        return image, label\n",
    "\n",
    "    @staticmethod\n",
    "    def elastic_deform(image, label, alpha, gaussian_kernel):\n",
    "        \"\"\"apply smooth elastic deformation on image and label data as\n",
    "        described in\n",
    "\n",
    "        [Simard2003] \"Best Practices for Convolutional Neural Networks applied\n",
    "        to Visual Document Analysis\"\n",
    "\n",
    "        Args:\n",
    "            image (torch tensor): extrapolated image tensor [1, 572, 572]\n",
    "            label (torch tensor): label tensor [1, 388, 388]\n",
    "            alpha (float): intensity of transformation\n",
    "            gaussian_kernel (np array): gaussian kernel used for smoothing\n",
    "\n",
    "        Returns:\n",
    "            deformed_img (torch tensor): deformed image tensor [1, 572, 572]\n",
    "            deformed_label (torch tensor): deformed label tensor [1, 388, 388]\n",
    "\n",
    "        code is adapted from https://github.com/vsvinayak/mnist-helper\n",
    "        \"\"\"\n",
    "        # generate standard coordinate grids\n",
    "        x_i, y_i = np.meshgrid(np.arange(572), np.arange(572))\n",
    "        x_l, y_l = np.meshgrid(np.arange(388), np.arange(388))\n",
    "        # generate random displacement fields (uniform distribution [-1, 1])\n",
    "        dx = 2*np.random.rand(*x_i.shape) - 1\n",
    "        dy = 2*np.random.rand(*y_i.shape) - 1\n",
    "        # smooth by convolving with gaussian kernel\n",
    "        dx = alpha * convolve2d(dx, gaussian_kernel, mode='same')\n",
    "        dy = alpha * convolve2d(dy, gaussian_kernel, mode='same')\n",
    "        # one dimensional coordinates (neccessary for map_coordinates)\n",
    "        x_img = np.reshape(x_i + dx, (-1, 1))\n",
    "        y_img = np.reshape(y_i + dy, (-1, 1))\n",
    "        x_label = np.reshape(x_l + dx[92:480, 92:480], (-1, 1))\n",
    "        y_label = np.reshape(y_l + dy[92:480, 92:480], (-1, 1))\n",
    "        # deformation using map_coordinates interpolation (spline not bicubic)\n",
    "        deformed_img = map_coordinates(image[0], [y_img, x_img], order=1,\n",
    "                                       mode='reflect')\n",
    "        deformed_label = map_coordinates(label[0], [y_label, x_label], order=1,\n",
    "                                         mode='reflect')\n",
    "        # reshape into desired shape and cast to tensor\n",
    "        deformed_img = torch.from_numpy(deformed_img.reshape(image.shape))\n",
    "        deformed_label = torch.from_numpy(deformed_label.reshape(label.shape))\n",
    "        return deformed_img, deformed_label\n",
    "\n",
    "    @staticmethod\n",
    "    def _extrapolate_by_mirroring(data):\n",
    "        \"\"\"increase data by mirroring (needed for overlap-tile strategy)\n",
    "\n",
    "        Args:\n",
    "            data (torch tensor): shape [num_samples, 1, 512, 512]\n",
    "\n",
    "        Returns:\n",
    "            extrapol_data (torch tensor): shape [num_samples, 1, 696, 696]\n",
    "        \"\"\"\n",
    "        num_samples = len(data)\n",
    "        extrapol_data = torch.zeros(num_samples, 1, 696, 696)\n",
    "\n",
    "        # put data into center of extrapol data\n",
    "        extrapol_data[:,:, 92:92+512, 92:92+512] = data\n",
    "        # mirror left\n",
    "        extrapol_data[:,:, 92:92+512, 0:92] = data[:,:,:,0:92].flip(3)\n",
    "        # mirror right\n",
    "        extrapol_data[:,:, 92:92+512, 92+512::] = data[:,:,:,-92::].flip(3)\n",
    "        # mirror top\n",
    "        extrapol_data[:,:, 0:92,:] = extrapol_data[:,:,92:92+92,:].flip(2)\n",
    "        # mirror buttom\n",
    "        extrapol_data[:,:, 92+512::,:] = extrapol_data[:,:, 512:512+92,:].flip(2)\n",
    "        return extrapol_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_gaussian_kernel(kernel_dim, sigma):\n",
    "        \"\"\"returns a 2D Gaussian kernel with the standard deviation\n",
    "        denoted by sigma\n",
    "\n",
    "        Args:\n",
    "            kernel_dim (int): kernel size will be [kernel_dim, kernel_dim]\n",
    "            sigma (float): std dev of Gaussian (smoothing parameter)\n",
    "\n",
    "        Returns:\n",
    "            gaussian_kernel (numpy array): centered gaussian kernel\n",
    "\n",
    "        code is adapted from https://github.com/vsvinayak/mnist-helper\n",
    "        \"\"\"\n",
    "        # check if the dimension is odd\n",
    "        if kernel_dim % 2 == 0:\n",
    "            raise ValueError(\"Kernel dimension should be odd\")\n",
    "        # initialize the kernel\n",
    "        kernel = np.zeros((kernel_dim, kernel_dim), dtype=np.float16)\n",
    "        # calculate the center point\n",
    "        center = kernel_dim/2\n",
    "        # calculate the variance\n",
    "        variance = sigma ** 2\n",
    "        # calculate the normalization coefficeint\n",
    "        coeff = 1. / (2 * variance)\n",
    "        # create the kernel\n",
    "        for x in range(0, kernel_dim):\n",
    "            for y in range(0, kernel_dim):\n",
    "                x_val = abs(x - center)\n",
    "                y_val = abs(y - center)\n",
    "                numerator = x_val**2 + y_val**2\n",
    "                denom = 2*variance\n",
    "\n",
    "                kernel[x,y] = coeff * np.exp(-1. * numerator/denom)\n",
    "        # normalise it\n",
    "        return kernel/sum(sum(kernel))\n",
    "\n",
    "\n",
    "# generate datasets\n",
    "stride = 124\n",
    "whole_dataset = EM_Dataset(imgs, labels, stride=stride,\n",
    "                           transformation=True, probability=0.5, alpha=50,\n",
    "                           sigma=5, kernel_dim=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}