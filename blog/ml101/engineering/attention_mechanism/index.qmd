---
title: "How does the attention mechanism ([Attention is all you need](https://arxiv.org/abs/1706.03762)) work?"
draft: true
---

In essence, an **attention mechanism** can be intuitively understood as a means to assign individual
importance (or rather *attention*) to each entity in a collection of entities (e.g., words in a
sentence or pixels in an image) using some cues as input. Mathmatically, this translates into
**computing a weighted average over all entities in which the attention weights are obtained from
the attention cues**. 

More abstractly, the attention mechanism can be used to answer the following questions

* What entities (e.g., pixels or words) should we attend to or focus on?
* What entities (e.g., pixels or words) are relevant for the task at hand?

[Vaswani et al. (2017)](https://arxiv.org/abs/1706.03762) call their particular attention mechanism
**Scaled Dot-Product Attention**. Therein, the collection of entities is termed **values** and the
attention cues are termed **queries** and **keys**. Attention to particular values (entities) is
obtained by computing the weighted average over all values (entities) in which the **attention
weights** are obtained by combining the attention cues.

The attention cues (queries and keys) are vectors of length $d_k$ defined per value and can
be seen as two different answers to the same question: *How much attention should we put to this
entity?* The **alignment** between the attention cues is computed via the dot-product (hence the
name), additionally the **alignment scores** are passed through a *Softmax*-layer to obtain
normalized **attention weights**. Finally, these attention weights are used to compute the weighted
average. 

To speed things up, queries, keys and values are packed into matrices $\textbf{Q}, \textbf{K}
\in \mathbb{R}^{N_v \times d_k}$ and $\textbf{V} \in \mathbb{R}^{N_v \times d_v}$,
respectively. As a result, the concise formulation of Scaled Dot-Product Attention is given by 

$$
\text{Attention}(\textbf{Q}, \textbf{K}, \textbf{V}) = 
\underbrace{\text{softmax} 
	\left(
	%\overbrace{
	\frac {\textbf{Q} \textbf{K}^{\text{T}}} {\sqrt{d_k}}
	%}^{\text{attention alignment }  \textbf{L} \in }
	\right)
}_{\text{attention weight }\textbf{W} \in \mathbb{R}^{N_v \times N_v}} \textbf{V}
$$

in which $\frac{1}{\sqrt{d_k}}$ is an additional scalar which [Vaswani et al. (2017)](https://arxiv.org/abs/1706.03762) 
added to counter vanishing gradients (they hypothesize that for a higher cue dimension $d_k$ the 
dot-product might grow large in magnitude). 

The figure highlights how the corresponding vectors are packed into matrices, respectively.

| ![Matrix Packing for Scaled Dot-Product Attention](./img/matrix_packing.png "Matrix Packing for Dot-Product Attention") |
| :--         |
| **Matrix Packing for Scaled Dot-Product Attention** |

Keeping in mind that attention can be seen as computing a weighted average (on each dimension) over all 
entities $\textbf{V}$, it is obvious that the result has the same dimension as $\textbf{V}$. Below is 
a simple implementation of the attention mechanism. Note that in practice commonly $\textbf{Q}$, $\textbf{K}$ 
and $\textbf{V}$ are learnable matrices.


```{python}
#| code-fold: false

import torch 


def attention(
        query_matrix: torch.Tensor, 
        key_matrix: torch.Tensor, 
        value_matrix: torch.Tensor
    ) -> torch.Tensor:
    """Simplistic implementation of scaled dot-product attention.

    Args:
        query_matrix (torch.Tensor): shape [batch_size, N_v, d_k]
        key_matrix (torch.Tensor):   shape [batch_size, N_v, d_k]
        value_matrix (torch.Tensor): shape [batch_size, N_v, d_v]

    Returns
        torch.Tensor:                shape [batch_size, N_v, d_v]
    """
    scale_factor = 1 / math.sqrt(query.size(-1))
    # compute unnormalized attention weights of shape [batch_size, N_v, N_v] 
    attn_weights = scale_factor * query_matrix @ key_matrix.transpose(-2, -1)
    # normalize attention weights (i.e., sum over last dimension equal to one)
    normalized_attn_weights = torch.softmax(attn_weights, dim=-1)
    # compute result of shape [batch_size, N_v, d_v] 
    return normalized_attn_weights @ value_matrix
```

::: {.callout-tip collapse=false}
## Key, Query, Value - Naming 

Instead of the weighted average formulation above, the attention mechanism could also be 
viewed as a **retrieval process** in which we have a storage of **key-value** pairs 
(e.g., [dictionaries](https://docs.python.org/3/tutorial/datastructures.html#dictionaries)) 
and a corresponding **query** input. 

:::


::: {.callout-tip collapse=true}
##  Self-Attention

:::


::: {.callout-tip collapse=true}
##  Multihead-Attention

:::
